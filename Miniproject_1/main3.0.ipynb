{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on GPU\n",
    "\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "print(noisy_imgs_1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selct a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:10000]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size = 5, padding = (5 - 1) // 2)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size = 5, padding = (5 - 1) // 2)\n",
    "        self.convT1 = nn.ConvTranspose2d(10, 3, kernel_size = 5, padding = (5 - 1) // 2)\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size = 5, stride = 1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size = 4, stride = 2)\n",
    "        self.convT1 = nn.ConvTranspose2d(10, 10, kernel_size = 4, stride = 2)\n",
    "        self.convT2 = nn.ConvTranspose2d(10, 3, kernel_size = 5, stride = 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print('x',x.shape)\n",
    "        x = self.dropout(F.relu(self.conv2(x)))\n",
    "        #print('x',x.shape)\n",
    "        x = self.dropout(F.relu(self.convT1(x)))\n",
    "        #print('x',x.shape)\n",
    "        x = F.sigmoid(self.convT2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For mini - project 1\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "    ## instantiate model + optimizer + loss function + any other stuff you need\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.autoenc = Net().to(self.device)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.autoenc.parameters(), lr = 1e-2)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "    ## This loads the parameters saved in bestmodel .pth into the model\n",
    "        self.autoenc  = model.load_state_dict(torch.load('bestmodel.pth'),strict=False)\n",
    "        pass\n",
    "\n",
    "    def train(self , train_input , train_target , mini_batch_size):\n",
    "    #: train˙input : tensor of size (N, C, H, W) containing a noisy version of the images.\n",
    "\n",
    "        train_input, train_target = train_input.to(self.device), train_target.to(self.device) # Use GPU\n",
    "        \n",
    "        nb_epochs = 20\n",
    "        #et\n",
    "\n",
    "        for epoch in range(nb_epochs):\n",
    "            acc_loss = 0\n",
    "\n",
    "            for b in range(0, train_input.size(0), mini_batch_size):\n",
    "                output = self.autoenc(train_input.narrow(0, b, mini_batch_size))\n",
    "                loss = self.criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "                acc_loss = acc_loss + loss.item()\n",
    "                #print('output', output.shape)\n",
    "                #print('loss',loss.shape, loss)\n",
    "                #print('acc loss', acc_loss)\n",
    "\n",
    "                #self.autoenc.zero_grad()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                #print('optimiser',self.optimizer)\n",
    "                #print(loss.grad)\n",
    "                #print(self.autoenc.conv1.input.grad.shape)\n",
    "                print('grad',self.autoenc.conv2.weight.grad[0,0][0])\n",
    "                #print(self.autoenc.convT1.weight.grad.shape)\n",
    "                #print(self.autoenc.convT2.weight.grad.shape)\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \"\"\"\n",
    "                with torch.no_grad():\n",
    "                    for p in self.autoenc.parameters():\n",
    "                        p -= eta * p.grad\n",
    "                \"\"\"\n",
    "                        \n",
    "            if not epoch % 5: \n",
    "                print(epoch, acc_loss)\n",
    "\n",
    "    #: train˙target : tensor of size (N, C, H, W) containing another noisy version of the same images , which only differs from the input by their noise .\n",
    "        pass\n",
    "\n",
    "    def predict(self , test_input ):\n",
    "    #: test˙input : tensor of size (N1 , C, H, W) that has to be denoised by the trained or the loaded network .\n",
    "    #: returns a tensor of the size (N1 , C, H, W)\n",
    "    \n",
    "        torch.save(self.autoenc.state_dict(), 'bestmodel.pth')\n",
    "        output = self.autoenc(test_input)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    # Add a method \"load pretrained model\" to load the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr ( denoised , ground_truth ) :\n",
    "        # Peak Signal to Noise Ratio : denoised and ground_truth have range [0 , 1]\n",
    "        mse = torch.mean (( denoised - ground_truth ) ** 2)\n",
    "        return -10 * torch.log10 ( mse + 10** -8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ici\n",
      "grad tensor([-5.0753e-05, -5.5815e-05, -6.2262e-05, -6.2338e-05])\n",
      "grad tensor([0.0009, 0.0010, 0.0010, 0.0010])\n",
      "grad tensor([-1.2351e-04, -1.0401e-04, -9.3690e-05, -8.0955e-05])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0002])\n",
      "grad tensor([-0.0011, -0.0011, -0.0011, -0.0010])\n",
      "grad tensor([0.0016, 0.0016, 0.0016, 0.0017])\n",
      "grad tensor([-0.0044, -0.0044, -0.0044, -0.0043])\n",
      "grad tensor([-0.0030, -0.0031, -0.0031, -0.0030])\n",
      "grad tensor([0.0076, 0.0075, 0.0076, 0.0078])\n",
      "grad tensor([-0.0006, -0.0007, -0.0007, -0.0005])\n",
      "0 0.7078900299966335\n",
      "grad tensor([-0.0104, -0.0105, -0.0105, -0.0103])\n",
      "grad tensor([-0.0017, -0.0019, -0.0018, -0.0017])\n",
      "grad tensor([0.0122, 0.0121, 0.0121, 0.0124])\n",
      "grad tensor([0.0047, 0.0046, 0.0047, 0.0048])\n",
      "grad tensor([-0.0064, -0.0065, -0.0065, -0.0064])\n",
      "grad tensor([-0.0115, -0.0116, -0.0116, -0.0114])\n",
      "grad tensor([-0.0085, -0.0087, -0.0086, -0.0085])\n",
      "grad tensor([0.0009, 0.0008, 0.0008, 0.0010])\n",
      "grad tensor([0.0102, 0.0100, 0.0100, 0.0102])\n",
      "grad tensor([0.0069, 0.0068, 0.0067, 0.0069])\n",
      "grad tensor([-0.0058, -0.0060, -0.0060, -0.0058])\n",
      "grad tensor([-0.0079, -0.0081, -0.0080, -0.0079])\n",
      "grad tensor([-0.0026, -0.0028, -0.0028, -0.0027])\n",
      "grad tensor([0.0068, 0.0066, 0.0066, 0.0067])\n",
      "grad tensor([0.0077, 0.0075, 0.0075, 0.0076])\n",
      "grad tensor([-0.0018, -0.0020, -0.0021, -0.0020])\n",
      "grad tensor([-0.0091, -0.0093, -0.0094, -0.0093])\n",
      "grad tensor([-0.0062, -0.0064, -0.0065, -0.0064])\n",
      "grad tensor([0.0073, 0.0070, 0.0069, 0.0070])\n",
      "grad tensor([0.0105, 0.0102, 0.0101, 0.0101])\n",
      "grad tensor([-0.0054, -0.0057, -0.0058, -0.0058])\n",
      "grad tensor([-0.0088, -0.0091, -0.0092, -0.0091])\n",
      "grad tensor([0.0066, 0.0063, 0.0062, 0.0062])\n",
      "grad tensor([0.0110, 0.0107, 0.0105, 0.0106])\n",
      "grad tensor([-0.0046, -0.0049, -0.0051, -0.0050])\n",
      "grad tensor([-0.0081, -0.0085, -0.0087, -0.0087])\n",
      "grad tensor([0.0083, 0.0081, 0.0080, 0.0080])\n",
      "grad tensor([0.0074, 0.0072, 0.0071, 0.0071])\n",
      "grad tensor([-0.0080, -0.0083, -0.0084, -0.0083])\n",
      "grad tensor([-0.0031, -0.0034, -0.0035, -0.0034])\n",
      "grad tensor([0.0060, 0.0059, 0.0058, 0.0059])\n",
      "grad tensor([0.0033, 0.0031, 0.0031, 0.0032])\n",
      "grad tensor([-0.0055, -0.0057, -0.0058, -0.0057])\n",
      "grad tensor([-0.0038, -0.0040, -0.0041, -0.0040])\n",
      "grad tensor([0.0030, 0.0029, 0.0029, 0.0030])\n",
      "grad tensor([0.0025, 0.0024, 0.0023, 0.0024])\n",
      "grad tensor([-0.0028, -0.0029, -0.0030, -0.0029])\n",
      "grad tensor([-0.0038, -0.0040, -0.0040, -0.0039])\n",
      "grad tensor([0.0005, 0.0004, 0.0003, 0.0004])\n",
      "grad tensor([0.0032, 0.0030, 0.0030, 0.0031])\n",
      "grad tensor([-0.0011, -0.0012, -0.0013, -0.0012])\n",
      "grad tensor([-0.0031, -0.0032, -0.0033, -0.0032])\n",
      "grad tensor([0.0005, 0.0003, 0.0003, 0.0004])\n",
      "grad tensor([0.0034, 0.0033, 0.0033, 0.0033])\n",
      "grad tensor([-0.0005, -0.0007, -0.0007, -0.0007])\n",
      "grad tensor([-0.0030, -0.0032, -0.0033, -0.0032])\n",
      "grad tensor([0.0030, 0.0029, 0.0029, 0.0028])\n",
      "grad tensor([0.0019, 0.0018, 0.0017, 0.0017])\n",
      "grad tensor([-0.0029, -0.0031, -0.0032, -0.0032])\n",
      "grad tensor([0.0011, 0.0010, 0.0009, 0.0008])\n",
      "5 0.37051377445459366\n",
      "grad tensor([0.0025, 0.0024, 0.0024, 0.0023])\n",
      "grad tensor([-0.0016, -0.0018, -0.0019, -0.0019])\n",
      "grad tensor([-0.0013, -0.0014, -0.0014, -0.0014])\n",
      "grad tensor([0.0022, 0.0021, 0.0021, 0.0020])\n",
      "grad tensor([-0.0003, -0.0004, -0.0005, -0.0005])\n",
      "grad tensor([-0.0019, -0.0021, -0.0021, -0.0021])\n",
      "grad tensor([0.0013, 0.0013, 0.0012, 0.0012])\n",
      "grad tensor([0.0005, 0.0004, 0.0004, 0.0003])\n",
      "grad tensor([-0.0022, -0.0023, -0.0023, -0.0023])\n",
      "grad tensor([0.0009, 0.0008, 0.0008, 0.0008])\n",
      "grad tensor([0.0010, 0.0010, 0.0009, 0.0009])\n",
      "grad tensor([-0.0016, -0.0016, -0.0017, -0.0017])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0002])\n",
      "grad tensor([0.0016, 0.0015, 0.0015, 0.0014])\n",
      "grad tensor([-0.0008, -0.0009, -0.0009, -0.0009])\n",
      "grad tensor([-0.0007, -0.0008, -0.0008, -0.0008])\n",
      "grad tensor([0.0018, 0.0018, 0.0018, 0.0017])\n",
      "grad tensor([-0.0007, -0.0007, -0.0008, -0.0009])\n",
      "grad tensor([-0.0011, -0.0012, -0.0012, -0.0012])\n",
      "grad tensor([0.0018, 0.0018, 0.0018, 0.0017])\n",
      "grad tensor([-0.0007, -0.0008, -0.0008, -0.0008])\n",
      "grad tensor([-0.0011, -0.0012, -0.0012, -0.0012])\n",
      "grad tensor([0.0012, 0.0012, 0.0012, 0.0011])\n",
      "grad tensor([-0.0002, -0.0002, -0.0003, -0.0003])\n",
      "grad tensor([-0.0010, -0.0010, -0.0011, -0.0011])\n",
      "grad tensor([0.0009, 0.0009, 0.0008, 0.0008])\n",
      "grad tensor([ 3.6289e-05,  1.2048e-05, -3.9673e-05, -1.0132e-04])\n",
      "grad tensor([-0.0011, -0.0011, -0.0012, -0.0013])\n",
      "grad tensor([0.0009, 0.0009, 0.0009, 0.0008])\n",
      "grad tensor([0.0003, 0.0002, 0.0002, 0.0001])\n",
      "grad tensor([-0.0013, -0.0013, -0.0014, -0.0014])\n",
      "grad tensor([0.0009, 0.0009, 0.0009, 0.0008])\n",
      "grad tensor([0.0004, 0.0004, 0.0003, 0.0003])\n",
      "grad tensor([-0.0011, -0.0011, -0.0012, -0.0012])\n",
      "grad tensor([0.0011, 0.0011, 0.0010, 0.0010])\n",
      "grad tensor([-4.1945e-05, -6.7302e-05, -1.1165e-04, -1.5986e-04])\n",
      "grad tensor([-0.0004, -0.0005, -0.0005, -0.0005])\n",
      "grad tensor([0.0003, 0.0003, 0.0002, 0.0001])\n",
      "grad tensor([-1.2361e-05, -3.0760e-05, -5.5755e-05, -1.0225e-04])\n",
      "grad tensor([-8.9759e-05, -1.3644e-04, -1.6122e-04, -2.2214e-04])\n",
      "grad tensor([8.9324e-05, 7.8992e-05, 4.4620e-05, 5.9080e-06])\n",
      "grad tensor([-2.9661e-05, -5.8604e-05, -1.0090e-04, -1.4652e-04])\n",
      "grad tensor([-3.6273e-05, -4.8925e-05, -6.6814e-05, -8.7091e-05])\n",
      "grad tensor([0.0002, 0.0002, 0.0002, 0.0001])\n",
      "grad tensor([-7.6846e-05, -1.0010e-04, -1.4501e-04, -1.9735e-04])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0003])\n",
      "grad tensor([0.0004, 0.0004, 0.0003, 0.0003])\n",
      "grad tensor([-0.0003, -0.0003, -0.0004, -0.0004])\n",
      "grad tensor([-9.9910e-05, -1.0656e-04, -1.2293e-04, -1.7073e-04])\n",
      "grad tensor([0.0006, 0.0006, 0.0005, 0.0005])\n",
      "10 0.340937539935112\n",
      "grad tensor([-0.0005, -0.0005, -0.0005, -0.0005])\n",
      "grad tensor([0.0003, 0.0002, 0.0002, 0.0002])\n",
      "grad tensor([1.1872e-04, 1.0899e-04, 8.5163e-05, 3.9190e-05])\n",
      "grad tensor([-8.4513e-05, -9.9344e-05, -1.2936e-04, -1.7585e-04])\n",
      "grad tensor([1.8489e-04, 1.8130e-04, 1.4120e-04, 9.8652e-05])\n",
      "grad tensor([-7.0273e-05, -8.0282e-05, -1.1170e-04, -1.4381e-04])\n",
      "grad tensor([1.2893e-04, 1.1840e-04, 8.3687e-05, 3.6778e-05])\n",
      "grad tensor([-0.0003, -0.0003, -0.0003, -0.0004])\n",
      "grad tensor([7.7936e-05, 5.9139e-05, 4.1103e-05, 8.1643e-07])\n",
      "grad tensor([0.0004, 0.0004, 0.0004, 0.0003])\n",
      "grad tensor([-0.0007, -0.0008, -0.0008, -0.0008])\n",
      "grad tensor([0.0008, 0.0008, 0.0007, 0.0007])\n",
      "grad tensor([-0.0002, -0.0003, -0.0003, -0.0003])\n",
      "grad tensor([-8.0044e-05, -1.1666e-04, -1.4536e-04, -1.7173e-04])\n",
      "grad tensor([0.0007, 0.0007, 0.0007, 0.0006])\n",
      "grad tensor([-0.0010, -0.0011, -0.0011, -0.0011])\n",
      "grad tensor([0.0011, 0.0011, 0.0011, 0.0010])\n",
      "grad tensor([-0.0009, -0.0010, -0.0010, -0.0010])\n",
      "grad tensor([0.0004, 0.0004, 0.0004, 0.0003])\n",
      "grad tensor([0.0005, 0.0005, 0.0004, 0.0004])\n",
      "grad tensor([-0.0007, -0.0008, -0.0008, -0.0008])\n",
      "grad tensor([0.0010, 0.0010, 0.0010, 0.0010])\n",
      "grad tensor([-0.0009, -0.0010, -0.0010, -0.0010])\n",
      "grad tensor([0.0006, 0.0006, 0.0006, 0.0005])\n",
      "grad tensor([-8.3873e-05, -8.8280e-05, -1.2431e-04, -1.5777e-04])\n",
      "grad tensor([-0.0004, -0.0004, -0.0004, -0.0004])\n",
      "grad tensor([0.0008, 0.0008, 0.0008, 0.0007])\n",
      "grad tensor([-0.0009, -0.0010, -0.0010, -0.0010])\n",
      "grad tensor([0.0010, 0.0010, 0.0010, 0.0010])\n",
      "grad tensor([-0.0006, -0.0006, -0.0006, -0.0007])\n",
      "grad tensor([0.0004, 0.0004, 0.0004, 0.0003])\n",
      "grad tensor([-8.7528e-05, -1.0379e-04, -1.3114e-04, -1.6070e-04])\n",
      "grad tensor([-2.2080e-05, -2.7282e-05, -4.4862e-05, -6.0649e-05])\n",
      "grad tensor([0.0002, 0.0002, 0.0002, 0.0002])\n",
      "grad tensor([-0.0004, -0.0004, -0.0004, -0.0004])\n",
      "grad tensor([0.0004, 0.0004, 0.0004, 0.0004])\n",
      "grad tensor([-0.0004, -0.0004, -0.0004, -0.0004])\n",
      "grad tensor([0.0004, 0.0005, 0.0004, 0.0004])\n",
      "grad tensor([-0.0005, -0.0006, -0.0006, -0.0006])\n",
      "grad tensor([0.0008, 0.0008, 0.0008, 0.0008])\n",
      "grad tensor([-0.0009, -0.0009, -0.0009, -0.0009])\n",
      "grad tensor([0.0007, 0.0007, 0.0007, 0.0007])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0002])\n",
      "grad tensor([0.0002, 0.0002, 0.0002, 0.0001])\n",
      "grad tensor([0.0004, 0.0004, 0.0004, 0.0003])\n",
      "grad tensor([-0.0005, -0.0005, -0.0006, -0.0006])\n",
      "grad tensor([0.0008, 0.0008, 0.0008, 0.0008])\n",
      "grad tensor([-0.0009, -0.0009, -0.0010, -0.0010])\n",
      "grad tensor([0.0010, 0.0010, 0.0010, 0.0010])\n",
      "grad tensor([-0.0009, -0.0009, -0.0009, -0.0009])\n",
      "15 0.32634421065449715\n",
      "grad tensor([0.0007, 0.0008, 0.0007, 0.0007])\n",
      "grad tensor([-0.0001, -0.0002, -0.0002, -0.0002])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad tensor([-9.6622e-05, -9.3630e-05, -1.1984e-04, -1.3259e-04])\n",
      "grad tensor([0.0008, 0.0008, 0.0008, 0.0008])\n",
      "grad tensor([-0.0009, -0.0009, -0.0009, -0.0009])\n",
      "grad tensor([0.0010, 0.0011, 0.0010, 0.0010])\n",
      "grad tensor([-0.0006, -0.0006, -0.0006, -0.0006])\n",
      "grad tensor([ 6.9177e-05,  6.0611e-05,  2.7850e-05, -9.8424e-07])\n",
      "grad tensor([0.0005, 0.0005, 0.0005, 0.0005])\n",
      "grad tensor([-0.0007, -0.0007, -0.0007, -0.0008])\n",
      "grad tensor([0.0008, 0.0009, 0.0008, 0.0008])\n",
      "grad tensor([-0.0006, -0.0006, -0.0006, -0.0006])\n",
      "grad tensor([0.0005, 0.0005, 0.0005, 0.0005])\n",
      "grad tensor([1.3804e-04, 1.3105e-04, 1.0369e-04, 7.4398e-05])\n",
      "grad tensor([-0.0003, -0.0002, -0.0003, -0.0003])\n",
      "grad tensor([0.0005, 0.0005, 0.0005, 0.0005])\n",
      "grad tensor([-0.0002, -0.0003, -0.0003, -0.0003])\n",
      "grad tensor([ 5.0222e-05,  5.3899e-05,  1.9681e-05, -8.7227e-06])\n",
      "grad tensor([7.1691e-05, 7.4042e-05, 5.8588e-05, 3.7672e-05])\n",
      "grad tensor([7.5184e-05, 8.7086e-05, 6.2170e-05, 3.8020e-05])\n",
      "grad tensor([ 7.1482e-06,  6.2985e-06,  1.2991e-06, -7.7798e-06])\n",
      "grad tensor([-1.0441e-05, -1.0385e-05, -2.6429e-05, -3.4606e-05])\n",
      "grad tensor([-7.7510e-05, -7.6784e-05, -8.2112e-05, -8.5993e-05])\n",
      "grad tensor([0.0003, 0.0003, 0.0003, 0.0003])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0002])\n",
      "grad tensor([0.0003, 0.0003, 0.0003, 0.0002])\n",
      "grad tensor([-0.0002, -0.0002, -0.0002, -0.0002])\n",
      "grad tensor([0.0002, 0.0002, 0.0001, 0.0001])\n",
      "grad tensor([-4.6766e-05, -4.4525e-05, -5.7136e-05, -6.5265e-05])\n",
      "grad tensor([0.0002, 0.0002, 0.0002, 0.0001])\n",
      "grad tensor([-0.0001, -0.0001, -0.0001, -0.0001])\n",
      "grad tensor([0.0003, 0.0003, 0.0003, 0.0003])\n",
      "grad tensor([-0.0004, -0.0005, -0.0005, -0.0005])\n",
      "grad tensor([0.0009, 0.0009, 0.0009, 0.0009])\n",
      "grad tensor([-0.0013, -0.0014, -0.0014, -0.0014])\n",
      "grad tensor([0.0018, 0.0018, 0.0018, 0.0018])\n",
      "grad tensor([-0.0020, -0.0021, -0.0021, -0.0021])\n",
      "grad tensor([0.0020, 0.0021, 0.0021, 0.0020])\n",
      "grad tensor([-0.0016, -0.0017, -0.0017, -0.0017])\n",
      "grad tensor([0.0010, 0.0010, 0.0010, 0.0010])\n",
      "psnr tensor(16.8861, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mini_batch_size = 1000\n",
    "\n",
    "model = Model()\n",
    "print('ici')\n",
    "model.train( imgs_1, imgs_2, mini_batch_size)\n",
    "\n",
    "out = model.predict(noisy_imgs)\n",
    "\n",
    "img_denoise_psnr = psnr(out ,clean_imgs )\n",
    "\n",
    "\n",
    "print(\"psnr\", img_denoise_psnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHAGE\n",
    "print(out[1].shape)\n",
    "\"\"\"\n",
    "#print(clean_imgs[1])\n",
    "plt.imshow(clean_imgs[1].permute(1,2,0))\n",
    "plt.show()\n",
    "plt.imshow(out[1].permute(1,2,0).detach())\n",
    "plt.show()\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "\n",
    "axs[0].imshow(noisy_imgs[1].permute(1,2,0))\n",
    "axs[0].set_title('noisy')\n",
    "axs[1].imshow(clean_imgs[1].permute(1,2,0))\n",
    "axs[0].set_title('clean')\n",
    "axs[2].imshow(out[1].permute(1,2,0).detach())\n",
    "axs[0].set_title('predict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.nn.modules.module._IncompatibleKeys' as child module 'autoenc' (torch.nn.Module or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4feff4863378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoisy_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-e7dbf8a4af3d>\u001b[0m in \u001b[0;36mload_pretrained_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m## This loads the parameters saved in bestmodel .pth into the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoenc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bestmodel.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                     raise TypeError(\"cannot assign '{}' as child module '{}' \"\n\u001b[0m\u001b[0;32m   1213\u001b[0m                                     \u001b[1;34m\"(torch.nn.Module or None expected)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                                     .format(torch.typename(value), name))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot assign 'torch.nn.modules.module._IncompatibleKeys' as child module 'autoenc' (torch.nn.Module or None expected)"
     ]
    }
   ],
   "source": [
    "model_2 = Model()\n",
    "model_2.load_pretrained_model()\n",
    "out = model_2.predict(noisy_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
