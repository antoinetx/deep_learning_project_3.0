{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch . nn . functional import fold , unfold\n",
    "\n",
    "#to delete\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28c71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on GPU\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b51e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "# select a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:1]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n",
    "print(imgs_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e28cc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionTransposed(object):\n",
    "    def __init__(self, channels_input, channels_output, kernel_size, stride):\n",
    "        self.weight = torch.empty(channels_output, channels_input, kernel_size, kernel_size).normal_()\n",
    "        \n",
    "        self.channel_input = channels_input\n",
    "        #print('input channels', self.channel_input)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        print('weight',self.weight.shape)\n",
    "        \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        #print('forward')\n",
    "        _,_,H,W = imgs.shape\n",
    "        H_out = (H - 1)*self.stride + self.kernel_size \n",
    "        W_out = (W - 1)*self.stride + self.kernel_size \n",
    "        \n",
    "        #print('Hout Wout', H_out, W_out)\n",
    "        \n",
    "        self.x = imgs.permute(1, 2, 3, 0).reshape(self.channel_input, -1)\n",
    "        #print('x',self.x.shape)\n",
    "        self.y = (self.weight.reshape(self.channel_input, -1)).t().matmul(self.x)\n",
    "        #print('y',self.y.shape)\n",
    "        self.y = self.y.reshape(self.y.shape[0], -1, imgs.shape[0])\n",
    "        #print('y2',self.y.shape)\n",
    "        self.y = self.y.permute(2, 0, 1)\n",
    "        \n",
    "        #print(self.y.shape)\n",
    "        self.y = fold( self.y, (H_out, W_out), kernel_size=(self.kernel_size,self.kernel_size), stride=self.stride)\n",
    "        \n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a4363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(object):\n",
    "    def __init__(self, factor_size):\n",
    "        self.kernel = torch.ones(factor_size,factor_size)\n",
    "        #print(self.kernel.shape)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x0, x1, s1, s2 = x.shape\n",
    "        s3, s4 = self.kernel.shape\n",
    "        x = x.reshape(x0, x1, s1, 1, s2, 1)\n",
    "        self.kernel = self.kernel.reshape(1, s3, 1, s4)\n",
    "        return (x * self.kernel).reshape(x0, x1, s1 * s3, s2 * s4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e3832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(object):\n",
    "    def __init__(self, channels_input, channels_output, kernel_size, stride):\n",
    "        \n",
    "        self.weight = torch.empty(channels_output, channels_input, kernel_size, kernel_size).normal_()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.channels_output = channels_output\n",
    "\n",
    "        #print('weight',self.weight.shape)\n",
    "         \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        \n",
    "        _,_,H,W = imgs.shape\n",
    "        #print('h w ',H,W)\n",
    "        self.Hout = (H - self.kernel_size)/self.stride + 1\n",
    "        self.Wout = (H - self.kernel_size)/self.stride + 1\n",
    "        #print('Hout Wout', self.Hout, self.Wout)\n",
    "        \n",
    "        self.x = unfold(imgs, kernel_size = (self.kernel_size, self.kernel_size), stride = self.stride)\n",
    "        #print('x',self.x.shape)\n",
    "        self.y = self.x.transpose(1, 2).matmul(self.weight.view(self.channels_output, -1).t()).transpose(1, 2)\n",
    "        #print('y',self.y.shape)\n",
    "        self.y = fold(self.y, (int(self.Hout), int(self.Wout)),(1,1), stride = 1)\n",
    "        #self.y = self.y.view(1,10,15,15)\n",
    "        return self.y\n",
    "    \n",
    "\n",
    "    def backward(self,gradwrtoutput):\n",
    "        dL_dS = gradwrtoutput\n",
    "        dS_dX = self.kernel\n",
    "        \n",
    "        \n",
    "        \n",
    "        return None\n",
    "\n",
    "    def param(self):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d60eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "    def __init__(self):\n",
    "        self.conv1 = Convolution(3, 10, kernel_size = 4, stride = 2) # tensor(1,10,15,15)\n",
    "        self.conv2 = Convolution(10, 10, kernel_size = 5, stride = 2) # tensor (1,10,6,6)\n",
    "        #self.convT1 = ConvolutionTransposed(10, 10, kernel_size = 5, stride = 2)\n",
    "        #self.convT2 = ConvolutionTransposed(10, 32, kernel_size = 4, stride = 2)\n",
    "        \n",
    "        self.upsample = Upsample(3)\n",
    "        self.upsample2 = Upsample(2)\n",
    "        self.convSample1 = Convolution(10, 10, kernel_size = 2, stride = 1)\n",
    "        self.convSample2 = Convolution(10, 3, kernel_size = 3, stride = 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        print(x.shape)\n",
    "        y = self.conv1.forward(x)\n",
    "        print(y.shape)\n",
    "        y = self.conv2.forward(y)\n",
    "        print(y.shape)\n",
    "        \"\"\"\n",
    "        y = self.convT1.forward(y)\n",
    "        print(y.shape)\n",
    "        y = self.convT2.forward(y)\n",
    "        print(y.shape)\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        y = self.upsample.forward(y)\n",
    "        print('y',y.shape)\n",
    "        y = self.convSample1.forward(y)\n",
    "        print('y',y.shape)\n",
    "        y = self.upsample2.forward(y)\n",
    "        print('y',y.shape)\n",
    "        y = self.convSample2.forward(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def backward (self, *gradwrtoutput ) :\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7e7bf24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 10, 15, 15])\n",
      "torch.Size([1, 10, 6, 6])\n",
      "y torch.Size([1, 10, 18, 18])\n",
      "y torch.Size([1, 10, 17, 17])\n",
      "y torch.Size([1, 10, 34, 34])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "##main function\n",
    "\n",
    "autoencoder = Net()\n",
    "img = torch.randn(1,3,32,32)\n",
    "\n",
    "y = autoencoder.forward(img)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde8c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5392.5918,  5392.5923,  3902.9692,  ...,  4806.1782,\n",
      "            1716.7714,  1716.7714],\n",
      "          [ 5392.5918,  5392.5923,  3902.9692,  ...,  4806.1782,\n",
      "            1716.7714,  1716.7714],\n",
      "          [10037.5957, 10037.5957,  7235.0898,  ...,  3266.0505,\n",
      "            -240.5643,  -240.5637],\n",
      "          ...,\n",
      "          [ 7843.0088,  7843.0088,  4864.6289,  ...,   403.9839,\n",
      "            2099.4636,  2099.4634],\n",
      "          [ 7399.4932,  7399.4932,  7701.0068,  ...,   500.7463,\n",
      "            2873.5198,  2873.5188],\n",
      "          [ 7399.4932,  7399.4932,  7701.0068,  ...,   500.7463,\n",
      "            2873.5203,  2873.5193]],\n",
      "\n",
      "         [[-4219.1606, -4219.1606, -1620.4579,  ..., -5560.5459,\n",
      "           -4738.8511, -4738.8516],\n",
      "          [-4219.1606, -4219.1606, -1620.4579,  ..., -5560.5459,\n",
      "           -4738.8511, -4738.8516],\n",
      "          [-8884.6426, -8884.6426, -7844.5591,  ..., -4945.8149,\n",
      "           -2274.4565, -2274.4565],\n",
      "          ...,\n",
      "          [ 1728.0776,  1728.0771, -1317.3701,  ..., -3889.3252,\n",
      "           -3156.5452, -3156.5454],\n",
      "          [ 5224.3271,  5224.3271,  2869.1270,  ..., -5187.7402,\n",
      "           -3479.0530, -3479.0532],\n",
      "          [ 5224.3271,  5224.3271,  2869.1270,  ..., -5187.7402,\n",
      "           -3479.0532, -3479.0537]],\n",
      "\n",
      "         [[ 2078.7556,  2078.7554,  5513.5527,  ..., -7983.2939,\n",
      "           -9948.9707, -9948.9707],\n",
      "          [ 2078.7556,  2078.7554,  5513.5527,  ..., -7983.2939,\n",
      "           -9948.9707, -9948.9707],\n",
      "          [  580.4166,   580.4166,  2453.3362,  ..., -6955.0703,\n",
      "           -9657.0674, -9657.0674],\n",
      "          ...,\n",
      "          [ 5232.4805,  5232.4805,  8596.4570,  ...,  6224.1353,\n",
      "            7874.4224,  7874.4233],\n",
      "          [11848.6992, 11848.6992, 16786.6426,  ...,  7152.9053,\n",
      "            9937.8750,  9937.8770],\n",
      "          [11848.6992, 11848.6992, 16786.6426,  ...,  7152.9053,\n",
      "            9937.8750,  9937.8750]]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3bbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
