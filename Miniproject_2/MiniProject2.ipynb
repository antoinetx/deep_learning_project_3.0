{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch . nn . functional import fold , unfold\n",
    "\n",
    "#to delete\n",
    "from torch import nn\n",
    "from others.modules import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b51e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "# select a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:10000]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n",
    "print(imgs_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfe40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.sequence = Sequential(Convolution(3, 20, kernel_size = 4, stride = 2),\n",
    "                                   ReLU(),\n",
    "                                   Convolution(20,20, kernel_size = 3, stride = 2),\n",
    "                                   ReLU(),\n",
    "                                   Upsample(2),\n",
    "                                   Convolution(20,20, kernel_size = 3, stride = 1),\n",
    "                                   ReLU(),\n",
    "                                   Upsample(3),\n",
    "                                   Convolution(20,3, kernel_size = 5, stride = 1),\n",
    "                                   Sigmoid())\n",
    "                                   \n",
    "\n",
    "        self.criterion = MSE()\n",
    "        self.optimizer = SGD(self.sequence, 1e-2)\n",
    "        \n",
    "        self.nb_samples = 10000\n",
    "        self.epochs = 10\n",
    "        print('Model Initialisation')\n",
    "\n",
    "    def train(self,train_input,train_target):\n",
    "    \n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            if not epoch % 5: \n",
    "                    print('epoch',epoch)\n",
    "\n",
    "            for n in range(self.nb_samples):\n",
    "\n",
    "                if not n % 10000: \n",
    "                    print('sample: ', n)\n",
    "                    print('weight',self.sequence.layers[0].weight[0,0,0])\n",
    "                    print('grad',self.sequence.layers[0].grad[0,0,0])\n",
    "                #print('img', train_input[n:n+1].shape)\n",
    "\n",
    "                predict_img = self.sequence.forward(train_input[n:n+1])\n",
    "                #print('optimizer zero grad')\n",
    "                self.optimizer.zero_grad()\n",
    "                #print('prediction', predict_img.shape)\n",
    "                loss = self.criterion.forward(predict_img, train_target[n:n+1])\n",
    "                #print('loss backward', self.criterion.backward())\n",
    "                backward_img = self.sequence.backward(self.criterion.backward())\n",
    "                #if not n % 100:\n",
    "                    #print('loss', loss)\n",
    "                    #print('grad conv0',self.sequence.layers[0].grad[0,0,0])\n",
    "                    #print('grad sigmoid',self.sequence.layers[8].grad[0,0,0,0])\n",
    "                    #print('grad upsample',self.sequence.layers[7].grad[0,0,0,0])\n",
    "                    #print('grad relu',self.sequence.layers[6].grad[0,0,0,0])\n",
    "                    #print('*********************************************************************************')\n",
    "                self.optimizer.step()\n",
    "        \n",
    "\n",
    "        return backward_img\n",
    "    \n",
    "    def predict(self,test_input):\n",
    "        prediction = torch.empty(test_input.shape)\n",
    "            \n",
    "        for n in range(test_input.shape[0]):\n",
    "            prediction[n:n+1] = self.sequence.forward(test_input[n:n+1])\n",
    "\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05f8fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Initialisation\n",
      "epoch 0\n",
      "sample:  0\n",
      "weight tensor([-0.5274,  0.6232,  1.4121,  0.0452])\n",
      "grad tensor([1.3563e-19, 1.1096e+27, 7.1774e+22, 1.7754e+28])\n",
      "sample:  0\n",
      "weight tensor([-0.3683,  0.7760,  1.6218,  0.3457])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3681,  0.7771,  1.6216,  0.3460])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3697,  0.7740,  1.6198,  0.3464])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3690,  0.7751,  1.6204,  0.3462])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "epoch 5\n",
      "sample:  0\n",
      "weight tensor([-0.3691,  0.7750,  1.6203,  0.3461])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3692,  0.7750,  1.6202,  0.3459])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3693,  0.7749,  1.6201,  0.3458])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3693,  0.7748,  1.6200,  0.3456])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "sample:  0\n",
      "weight tensor([-0.3694,  0.7748,  1.6199,  0.3455])\n",
      "grad tensor([0., 0., 0., 0.])\n",
      "out img torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#img = torch.randn(1, 3, 32, 32)\n",
    "#img_error = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "output = model.train(imgs_1, imgs_2)\n",
    "\n",
    "\n",
    "\n",
    "print('out img', output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f7886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr ( denoised , ground_truth ) :\n",
    "        # Peak Signal to Noise Ratio : denoised and ground_truth have range [0 , 1]\n",
    "        mse = torch.mean (( denoised - ground_truth ) ** 2)\n",
    "        return -10 * torch.log10 ( mse + 10** -8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c13662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "torch.Size([1000, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(noisy_imgs.shape[0])\n",
    "\n",
    "prediction = model.predict(noisy_imgs)\n",
    "\n",
    "\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ffa9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_denoise_psnr = psnr(prediction ,clean_imgs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265d8008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr tensor(5.9272)\n"
     ]
    }
   ],
   "source": [
    "print(\"psnr\", img_denoise_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703e8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
