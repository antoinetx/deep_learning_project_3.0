{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch . nn . functional import fold , unfold\n",
    "\n",
    "#to delete\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c28c71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on GPU\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b51e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "# selct a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:1]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n",
    "print(imgs_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab7e444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2e28c8c879ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munf_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgs_1' is not defined"
     ]
    }
   ],
   "source": [
    "input_x = imgs_1\n",
    "print(input_x.shape)\n",
    "print(imgs_1.shape)\n",
    "\n",
    "unf_input = unfold(imgs_1, kernel_size=(5, 5))\n",
    "print(unf_input.shape)\n",
    "\n",
    "conv1 = nn.Conv2d(3, 10, kernel_size = 5, stride = 1)\n",
    "output_x = conv1(input_x)\n",
    "print(output_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff377e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-533105230462>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0munf_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munf_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mHout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mWout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgs_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(imgs_1.shape)\n",
    "unf_input = unfold(imgs_1, kernel_size=(5, 5))\n",
    "print(unf_input.shape)\n",
    "Hout = (32 - 5)/1 + 1\n",
    "Wout = (32 - 5)/1 + 1\n",
    "print(Hout, Wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([1, 3, 6, 6])\n",
      "y torch.Size([1, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(3, 3, 5, 5)\n",
    "\n",
    "x = torch.ones(1,3,6,6)\n",
    "\n",
    "convT1 = nn.ConvTranspose2d(3, 3, kernel_size = 5, stride = 1)\n",
    "\n",
    "y = convT1(x)\n",
    "print('x', x.shape)\n",
    "print('y',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e177b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 6, 6])\n",
      "x torch.Size([10, 36])\n",
      "w torch.Size([10, 75])\n",
      "y unfolded calculate torch.Size([75, 36])\n",
      "y torch.Size([75, 36, 1])\n",
      "y torch.Size([1, 75, 36])\n",
      "y fin torch.Size([1, 75, 36])\n",
      "torch.Size([1, 3, 10, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nH_in = self.x.shape[2]\\nW_in = self.x.shape[3]\\n\\n\\nreturn fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convtrans\n",
    "\n",
    "x = torch.ones(1,10,6,6)\n",
    "w = torch.randn(3, 10, 5, 5)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "x_reshape = x.permute(1, 2, 3, 0).reshape(10, -1)\n",
    "print('x',x_reshape.shape)\n",
    "w_reshape = w.reshape(10, -1)\n",
    "print('w', w_reshape.shape)\n",
    "y_unfolded = w_reshape.t().matmul(x_reshape)\n",
    "print('y unfolded calculate',y_unfolded.shape)\n",
    "\n",
    "y_unfolded = y_unfolded.reshape(y_unfolded.shape[0], -1, x.shape[0])\n",
    "print('y',y_unfolded.shape)\n",
    "y_unfolded = y_unfolded.permute(2, 0, 1)\n",
    "print('y',y_unfolded.shape)\n",
    "\n",
    "\n",
    "print('y fin', y_unfolded.shape)\n",
    "\n",
    "H_out = (6 - 1)*1+ (5 - 1) + 1\n",
    "W_out = (6 - 1)*1 + (5- 1) + 1\n",
    "\n",
    "ou_t = fold(y_unfolded, (H_out, W_out), kernel_size=(5,5), stride=1)\n",
    "print(ou_t.shape)\n",
    "\n",
    "\"\"\"\n",
    "H_in = self.x.shape[2]\n",
    "W_in = self.x.shape[3]\n",
    "\n",
    "\n",
    "return fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , x ) :\n",
    "        \n",
    "        x = convolution(x)\n",
    "\n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf4497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "torch.Size([1, 48, 9])\n",
      "3.0 3.0\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "print(imgs_1.shape)\n",
    "unf_input = unfold(imgs_1, kernel_size=(4,4))\n",
    "print(unf_input.shape)\n",
    "\n",
    "Hout = (6 - 4)/1 + 1\n",
    "Wout = (6 - 4)/1 + 1\n",
    "\n",
    "print(Hout,Wout)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b64cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 36]) torch.Size([1, 3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "\n",
    "a = imgs_1.reshape(1,3,-1)\n",
    "b = imgs_1\n",
    "\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17d33db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 25, 12])\n",
      "torch.Size([12, 3])\n",
      "permute mode\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([3, 12])\n",
      "torch.Size([1, 25, 3])\n",
      "torch.Size([1, 3, 25])\n",
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#Upsampling\n",
    "\n",
    "print(imgs_1.shape)\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "w = torch.randn(3, 3, 2, 2)\n",
    "\n",
    "unf_input = unfold(imgs_1, kernel_size=(2,2))\n",
    "print(unf_input.shape)\n",
    "\n",
    "out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "#out_unf = (w.view(w.size(0), -1).t()).matmul(unf_input.transpose(1, 2)).transpose(1, 2)\n",
    "print(unf_input.transpose(1, 2).shape)\n",
    "print(w.view(w.size(0), -1).t().shape)\n",
    "\n",
    "print('permute mode')\n",
    "print(unf_input.transpose(1, 2).permute(0,2,1).shape)\n",
    "print(w.view(w.size(0), -1).t().permute(1,0).shape)\n",
    "\n",
    "print(unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).shape)\n",
    "print(out_unf.shape)\n",
    "#out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35ec446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "_,_,H,W = imgs_1.shape\n",
    "print(H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79448ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "w torch.Size([10, 3, 2, 2])\n",
      "unf_input torch.Size([1, 12, 25])\n",
      "1 torch.Size([1, 25, 12])\n",
      "2 torch.Size([12, 10])\n",
      "out_unf  torch.Size([1, 10, 25])\n",
      "out torch.Size([1, 10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#convolution with no stride and kernel of 5\n",
    "\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "print(imgs_1.shape)\n",
    "\n",
    "\n",
    "def convolution(x):\n",
    "\n",
    "    w = torch.randn(10, 3, 2, 2)\n",
    "    print('w',w.shape)\n",
    "    \n",
    "    unf_input = unfold(imgs_1, kernel_size=(2, 2))\n",
    "    print('unf_input',unf_input.shape)\n",
    "    out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "    print('1',unf_input.transpose(1, 2).shape)\n",
    "    print('2',w.view(w.size(0), -1).t().shape)\n",
    "    print('out_unf ',out_unf.shape )\n",
    "    out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "    print('out',out.shape)\n",
    "    \n",
    "    return out\n",
    "\n",
    "y = convolution(imgs_1)\n",
    "\n",
    "#out_ = torch.nn.functional.fold(out_unf, (h_out, w_out), (1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7272fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "\n",
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67749e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential ( Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            Sigmoid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e973d3bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2636,  0.4540],\n",
      "          [ 0.4969, -0.7056]],\n",
      "\n",
      "         [[-0.7837,  1.8423],\n",
      "          [ 0.5035,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.0372],\n",
      "          [ 0.0666, -0.6049]]]])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[-0.2636,  0.4540,  0.4969, -0.7056, -0.7837,  1.8423,  0.5035,  0.3321,\n",
      "         -0.4469, -0.0372,  0.0666, -0.6049]])\n",
      "tensor([[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "        [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "        [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "        [-0.7056, -0.7056, -0.7056, -0.7056],\n",
      "        [-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "        [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "        [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "        [ 0.3321,  0.3321,  0.3321,  0.3321],\n",
      "        [-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "        [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "        [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "        [-0.6049, -0.6049, -0.6049, -0.6049]])\n",
      "torch.Size([1, 3, 4, 4]) torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "          [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "          [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "          [-0.7056, -0.7056, -0.7056, -0.7056]],\n",
      "\n",
      "         [[-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "          [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "          [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "          [ 0.3321,  0.3321,  0.3321,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "          [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "          [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "          [-0.6049, -0.6049, -0.6049, -0.6049]]]])\n",
      "tensor([[[[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "          [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "          [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "          [-0.7056, -0.7056, -0.7056, -0.7056]],\n",
      "\n",
      "         [[-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "          [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "          [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "          [ 0.3321,  0.3321,  0.3321,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "          [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "          [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "          [-0.6049, -0.6049, -0.6049, -0.6049]]]])\n"
     ]
    }
   ],
   "source": [
    "ac = torch.randn((1,3,2,2))\n",
    "print(ac)\n",
    "#ac_unfold = fold(ac.reshape(1,3,-1), (4, 4), (1, 1), dilation=(2, 2))\n",
    "#print('unfold',ac_unfold.shape)\n",
    "ac = ac.reshape(1,-1)\n",
    " \n",
    "\n",
    "print(ac.shape)\n",
    "#print(ac)\n",
    "#ac = ac.permute(0,2,1)\n",
    "w = torch.ones(1, 4)\n",
    "print(w.shape)\n",
    "print(w)\n",
    "print(ac)\n",
    "\n",
    "y = ac.T @ w\n",
    "print(y)\n",
    "#print(y.shape)\n",
    "y_view = y.view(1,3,4,4)\n",
    "y_reshape = y.reshape(1,3,4,4)\n",
    "\n",
    "print(y_view.shape, y_reshape.shape)\n",
    "print(y_view)\n",
    "print(y_reshape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37f0e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 75, 48])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (5, 5))\n",
    "print(inp_unf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40e711a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 1],\n",
      "          [5, 9]],\n",
      "\n",
      "         [[8, 5],\n",
      "          [8, 3]],\n",
      "\n",
      "         [[8, 1],\n",
      "          [7, 2]]]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[0., 0., 1., 1.],\n",
      "          [0., 0., 1., 1.],\n",
      "          [5., 5., 9., 9.],\n",
      "          [5., 5., 9., 9.]],\n",
      "\n",
      "         [[8., 8., 5., 5.],\n",
      "          [8., 8., 5., 5.],\n",
      "          [8., 8., 3., 3.],\n",
      "          [8., 8., 3., 3.]],\n",
      "\n",
      "         [[8., 8., 1., 1.],\n",
      "          [8., 8., 1., 1.],\n",
      "          [7., 7., 2., 2.],\n",
      "          [7., 7., 2., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "def upsample(a,factor_size):\n",
    "    \n",
    "    b = torch.ones(factor_size,factor_size)\n",
    "    print(b)\n",
    "    a0, a1, s1, s2 = a.shape\n",
    "    s3, s4 = b.shape\n",
    "    a = a.reshape(a0, a1, s1, 1, s2, 1)\n",
    "    b = b.reshape(1, s3, 1, s4)\n",
    "    return (a * b).reshape(a0, a1, s1 * s3, s2 * s4)\n",
    "\n",
    "a = torch.randint(10,(1,3,2,2))\n",
    "\n",
    "\n",
    "print(a)\n",
    "\n",
    "c = upsample(a,2)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbd49157",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-57-bf3db8bb2963>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-57-bf3db8bb2963>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    dl_dw1, dl_db1, dl_dw2, dl_db2):\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10,(1,10,6,6))\n",
    "print(a.shape)\n",
    "\n",
    "upsample = Upsample(3)\n",
    "upsample2 = Upsample(2)\n",
    "convSample1 = Convolution(10, 10, kernel_size = 2, stride = 1)\n",
    "convSample2 = Convolution(10, 3, kernel_size = 3, stride = 1)\n",
    "\n",
    "\n",
    "c = upsample.forward(a)\n",
    "print('c',c.shape)\n",
    "c = convSample1.forward(c)\n",
    "print('c',c.shape)\n",
    "c = upsample2.forward(c)\n",
    "print('c',c.shape)\n",
    "c = convSample2.forward(c)\n",
    "print('c',c.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
