{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch . nn . functional import fold , unfold\n",
    "\n",
    "#to delete\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c28c71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on GPU\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b51e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "# selct a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:1]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n",
    "print(imgs_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fab7e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 10, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_x = imgs_1\n",
    "print(input_x.shape)\n",
    "conv1 = nn.Conv2d(3, 10, kernel_size = 5, stride = 1)\n",
    "output_x = conv1(input_x)\n",
    "print(output_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff377e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 75, 784])\n"
     ]
    }
   ],
   "source": [
    "print(imgs_1.shape)\n",
    "unf_input = unfold(imgs_1, kernel_size=(5, 5))\n",
    "print(unf_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([1, 3, 6, 6])\n",
      "y torch.Size([1, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(3, 3, 5, 5)\n",
    "\n",
    "x = torch.ones(1,3,6,6)\n",
    "\n",
    "convT1 = nn.ConvTranspose2d(3, 3, kernel_size = 5, stride = 1)\n",
    "\n",
    "y = convT1(x)\n",
    "print('x', x.shape)\n",
    "print('y',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e177b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 6, 6])\n",
      "x torch.Size([10, 36])\n",
      "w torch.Size([10, 75])\n",
      "y unfolded calculate torch.Size([75, 36])\n",
      "y torch.Size([75, 36, 1])\n",
      "y torch.Size([1, 75, 36])\n",
      "y fin torch.Size([1, 75, 36])\n",
      "torch.Size([1, 3, 10, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nH_in = self.x.shape[2]\\nW_in = self.x.shape[3]\\n\\n\\nreturn fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convtrans\n",
    "\n",
    "x = torch.ones(1,10,6,6)\n",
    "w = torch.randn(3, 10, 5, 5)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "x_reshape = x.permute(1, 2, 3, 0).reshape(10, -1)\n",
    "print('x',x_reshape.shape)\n",
    "w_reshape = w.reshape(10, -1)\n",
    "print('w', w_reshape.shape)\n",
    "y_unfolded = w_reshape.t().matmul(x_reshape)\n",
    "print('y unfolded calculate',y_unfolded.shape)\n",
    "\n",
    "y_unfolded = y_unfolded.reshape(y_unfolded.shape[0], -1, x.shape[0])\n",
    "print('y',y_unfolded.shape)\n",
    "y_unfolded = y_unfolded.permute(2, 0, 1)\n",
    "print('y',y_unfolded.shape)\n",
    "\n",
    "\n",
    "print('y fin', y_unfolded.shape)\n",
    "\n",
    "H_out = (6 - 1)*1+ (5 - 1) + 1\n",
    "W_out = (6 - 1)*1 + (5- 1) + 1\n",
    "\n",
    "ou_t = fold(y_unfolded, (H_out, W_out), kernel_size=(5,5), stride=1)\n",
    "print(ou_t.shape)\n",
    "\n",
    "\"\"\"\n",
    "H_in = self.x.shape[2]\n",
    "W_in = self.x.shape[3]\n",
    "\n",
    "\n",
    "return fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , x ) :\n",
    "        \n",
    "        x = convolution(x)\n",
    "\n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ccf4497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 36])\n",
      "torch.Size([1, 3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "w = torch.randn(3, 3, 1, 1)\n",
    "unf_input = unfold(imgs_1, kernel_size=(1,1))\n",
    "print(unf_input.shape)\n",
    "out = nn.functional.fold(unf_input,(6,6),(1,1))\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17d33db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 25, 12])\n",
      "torch.Size([12, 3])\n",
      "permute mode\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([3, 12])\n",
      "torch.Size([1, 25, 3])\n",
      "torch.Size([1, 3, 25])\n",
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#Upsampling\n",
    "\n",
    "print(imgs_1.shape)\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "w = torch.randn(3, 3, 2, 2)\n",
    "\n",
    "unf_input = unfold(imgs_1, kernel_size=(2,2))\n",
    "print(unf_input.shape)\n",
    "\n",
    "out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "#out_unf = (w.view(w.size(0), -1).t()).matmul(unf_input.transpose(1, 2)).transpose(1, 2)\n",
    "print(unf_input.transpose(1, 2).shape)\n",
    "print(w.view(w.size(0), -1).t().shape)\n",
    "\n",
    "print('permute mode')\n",
    "print(unf_input.transpose(1, 2).permute(0,2,1).shape)\n",
    "print(w.view(w.size(0), -1).t().permute(1,0).shape)\n",
    "\n",
    "print(unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).shape)\n",
    "print(out_unf.shape)\n",
    "#out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35ec446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "_,_,H,W = imgs_1.shape\n",
    "print(H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79448ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "w torch.Size([10, 3, 2, 2])\n",
      "unf_input torch.Size([1, 12, 25])\n",
      "1 torch.Size([1, 25, 12])\n",
      "2 torch.Size([12, 10])\n",
      "out_unf  torch.Size([1, 10, 25])\n",
      "out torch.Size([1, 10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#convolution with no stride and kernel of 5\n",
    "\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "print(imgs_1.shape)\n",
    "\n",
    "\n",
    "def convolution(x):\n",
    "\n",
    "    w = torch.randn(10, 3, 2, 2)\n",
    "    print('w',w.shape)\n",
    "    \n",
    "    unf_input = unfold(imgs_1, kernel_size=(2, 2))\n",
    "    print('unf_input',unf_input.shape)\n",
    "    out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "    print('1',unf_input.transpose(1, 2).shape)\n",
    "    print('2',w.view(w.size(0), -1).t().shape)\n",
    "    print('out_unf ',out_unf.shape )\n",
    "    out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "    print('out',out.shape)\n",
    "    \n",
    "    return out\n",
    "\n",
    "y = convolution(imgs_1)\n",
    "\n",
    "#out_ = torch.nn.functional.fold(out_unf, (h_out, w_out), (1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7272fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "\n",
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67749e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential ( Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            Sigmoid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584247ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def dsigma(x):\n",
    "    return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "\n",
    "def loss(v, t):\n",
    "    return (v - t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d609d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    nb_channel = 1\n",
    "    stride = 1\n",
    "    H_filter = 3\n",
    "    W_filter = 3\n",
    "    \n",
    "    H_out = int(1 +(H  — H_filter)/stride)\n",
    "    W_out = int(1 +(W — W_filter)/stride)\n",
    "    \n",
    "\n",
    "    for i in range(H_out):\n",
    "        for j in range(W_out):\n",
    "            out[i, j] = np.sum(x[n, :, i*stride:i*stride+H_filter, j*stride : j*stride + W_filter] * w[f] ) + b[f]\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd49157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
