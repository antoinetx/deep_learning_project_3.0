{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67a7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch\n",
    "from torch import empty , cat , arange\n",
    "from torch . nn . functional import fold , unfold\n",
    "\n",
    "#to delete\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28c71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put on GPU\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b51e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Extract images\n",
    "\n",
    "noisy_imgs_1 , noisy_imgs_2 = torch.load('data/train_data.pkl')\n",
    "noisy_imgs , clean_imgs = torch.load ('data/val_data.pkl')\n",
    "\n",
    "noisy_imgs = noisy_imgs/255\n",
    "clean_imgs = clean_imgs/255\n",
    "\n",
    "# selct a preset of images:\n",
    "\n",
    "imgs_1 = noisy_imgs_1[:1]/255\n",
    "imgs_2 = noisy_imgs_2[:10000]/255\n",
    "print(imgs_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab7e444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2e28c8c879ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munf_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgs_1' is not defined"
     ]
    }
   ],
   "source": [
    "input_x = imgs_1\n",
    "print(input_x.shape)\n",
    "print(imgs_1.shape)\n",
    "\n",
    "unf_input = unfold(imgs_1, kernel_size=(5, 5))\n",
    "print(unf_input.shape)\n",
    "\n",
    "conv1 = nn.Conv2d(3, 10, kernel_size = 5, stride = 1)\n",
    "output_x = conv1(input_x)\n",
    "print(output_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff377e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-533105230462>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0munf_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munf_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mHout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mWout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgs_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(imgs_1.shape)\n",
    "unf_input = unfold(imgs_1, kernel_size=(5, 5))\n",
    "print(unf_input.shape)\n",
    "Hout = (32 - 5)/1 + 1\n",
    "Wout = (32 - 5)/1 + 1\n",
    "print(Hout, Wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4c28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([1, 3, 6, 6])\n",
      "y torch.Size([1, 3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(3, 3, 5, 5)\n",
    "\n",
    "x = torch.ones(1,3,6,6)\n",
    "\n",
    "convT1 = nn.ConvTranspose2d(3, 3, kernel_size = 5, stride = 1)\n",
    "\n",
    "y = convT1(x)\n",
    "print('x', x.shape)\n",
    "print('y',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e177b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 6, 6])\n",
      "x torch.Size([10, 36])\n",
      "w torch.Size([10, 75])\n",
      "y unfolded calculate torch.Size([75, 36])\n",
      "y torch.Size([75, 36, 1])\n",
      "y torch.Size([1, 75, 36])\n",
      "y fin torch.Size([1, 75, 36])\n",
      "torch.Size([1, 3, 10, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nH_in = self.x.shape[2]\\nW_in = self.x.shape[3]\\n\\n\\nreturn fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convtrans\n",
    "\n",
    "x = torch.ones(1,10,6,6)\n",
    "w = torch.randn(3, 10, 5, 5)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "x_reshape = x.permute(1, 2, 3, 0).reshape(10, -1)\n",
    "print('x',x_reshape.shape)\n",
    "w_reshape = w.reshape(10, -1)\n",
    "print('w', w_reshape.shape)\n",
    "y_unfolded = w_reshape.t().matmul(x_reshape)\n",
    "print('y unfolded calculate',y_unfolded.shape)\n",
    "\n",
    "y_unfolded = y_unfolded.reshape(y_unfolded.shape[0], -1, x.shape[0])\n",
    "print('y',y_unfolded.shape)\n",
    "y_unfolded = y_unfolded.permute(2, 0, 1)\n",
    "print('y',y_unfolded.shape)\n",
    "\n",
    "\n",
    "print('y fin', y_unfolded.shape)\n",
    "\n",
    "H_out = (6 - 1)*1+ (5 - 1) + 1\n",
    "W_out = (6 - 1)*1 + (5- 1) + 1\n",
    "\n",
    "ou_t = fold(y_unfolded, (H_out, W_out), kernel_size=(5,5), stride=1)\n",
    "print(ou_t.shape)\n",
    "\n",
    "\"\"\"\n",
    "H_in = self.x.shape[2]\n",
    "W_in = self.x.shape[3]\n",
    "\n",
    "\n",
    "return fold(y_unfolded, (H_out, W_out), kernel_size=self.kernel_size, stride=self.stride) + self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( object ) :\n",
    "    def forward ( self , x ) :\n",
    "        \n",
    "        x = convolution(x)\n",
    "\n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf4497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "torch.Size([1, 48, 9])\n",
      "3.0 3.0\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "print(imgs_1.shape)\n",
    "unf_input = unfold(imgs_1, kernel_size=(4,4))\n",
    "print(unf_input.shape)\n",
    "\n",
    "Hout = (6 - 4)/1 + 1\n",
    "Wout = (6 - 4)/1 + 1\n",
    "\n",
    "print(Hout,Wout)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b64cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 36]) torch.Size([1, 3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "\n",
    "a = imgs_1.reshape(1,3,-1)\n",
    "b = imgs_1\n",
    "\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17d33db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([1, 25, 12])\n",
      "torch.Size([12, 3])\n",
      "permute mode\n",
      "torch.Size([1, 12, 25])\n",
      "torch.Size([3, 12])\n",
      "torch.Size([1, 25, 3])\n",
      "torch.Size([1, 3, 25])\n",
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#Upsampling\n",
    "\n",
    "print(imgs_1.shape)\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "w = torch.randn(3, 3, 2, 2)\n",
    "\n",
    "unf_input = unfold(imgs_1, kernel_size=(2,2))\n",
    "print(unf_input.shape)\n",
    "\n",
    "out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "#out_unf = (w.view(w.size(0), -1).t()).matmul(unf_input.transpose(1, 2)).transpose(1, 2)\n",
    "print(unf_input.transpose(1, 2).shape)\n",
    "print(w.view(w.size(0), -1).t().shape)\n",
    "\n",
    "print('permute mode')\n",
    "print(unf_input.transpose(1, 2).permute(0,2,1).shape)\n",
    "print(w.view(w.size(0), -1).t().permute(1,0).shape)\n",
    "\n",
    "print(unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).shape)\n",
    "print(out_unf.shape)\n",
    "#out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35ec446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "_,_,H,W = imgs_1.shape\n",
    "print(H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79448ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6, 6])\n",
      "w torch.Size([10, 3, 2, 2])\n",
      "unf_input torch.Size([1, 12, 25])\n",
      "1 torch.Size([1, 25, 12])\n",
      "2 torch.Size([12, 10])\n",
      "out_unf  torch.Size([1, 10, 25])\n",
      "out torch.Size([1, 10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#convolution with no stride and kernel of 5\n",
    "\n",
    "imgs_1 = torch.ones(1,3,6,6)\n",
    "print(imgs_1.shape)\n",
    "\n",
    "\n",
    "def convolution(x):\n",
    "\n",
    "    w = torch.randn(10, 3, 2, 2)\n",
    "    print('w',w.shape)\n",
    "    \n",
    "    unf_input = unfold(imgs_1, kernel_size=(2, 2))\n",
    "    print('unf_input',unf_input.shape)\n",
    "    out_unf = unf_input.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "    print('1',unf_input.transpose(1, 2).shape)\n",
    "    print('2',w.view(w.size(0), -1).t().shape)\n",
    "    print('out_unf ',out_unf.shape )\n",
    "    out = nn.functional.fold(out_unf,(5, 5),(1,1))\n",
    "    print('out',out.shape)\n",
    "    \n",
    "    return out\n",
    "\n",
    "y = convolution(imgs_1)\n",
    "\n",
    "#out_ = torch.nn.functional.fold(out_unf, (h_out, w_out), (1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7272fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d8983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n",
    "\n",
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (4, 5))\n",
    "out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67749e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential ( Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Conv ( stride 2) ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            ReLU ,\n",
    "            Upsampling ,\n",
    "            Sigmoid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e973d3bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2636,  0.4540],\n",
      "          [ 0.4969, -0.7056]],\n",
      "\n",
      "         [[-0.7837,  1.8423],\n",
      "          [ 0.5035,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.0372],\n",
      "          [ 0.0666, -0.6049]]]])\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1., 1., 1., 1.]])\n",
      "tensor([[-0.2636,  0.4540,  0.4969, -0.7056, -0.7837,  1.8423,  0.5035,  0.3321,\n",
      "         -0.4469, -0.0372,  0.0666, -0.6049]])\n",
      "tensor([[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "        [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "        [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "        [-0.7056, -0.7056, -0.7056, -0.7056],\n",
      "        [-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "        [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "        [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "        [ 0.3321,  0.3321,  0.3321,  0.3321],\n",
      "        [-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "        [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "        [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "        [-0.6049, -0.6049, -0.6049, -0.6049]])\n",
      "torch.Size([1, 3, 4, 4]) torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "          [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "          [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "          [-0.7056, -0.7056, -0.7056, -0.7056]],\n",
      "\n",
      "         [[-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "          [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "          [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "          [ 0.3321,  0.3321,  0.3321,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "          [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "          [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "          [-0.6049, -0.6049, -0.6049, -0.6049]]]])\n",
      "tensor([[[[-0.2636, -0.2636, -0.2636, -0.2636],\n",
      "          [ 0.4540,  0.4540,  0.4540,  0.4540],\n",
      "          [ 0.4969,  0.4969,  0.4969,  0.4969],\n",
      "          [-0.7056, -0.7056, -0.7056, -0.7056]],\n",
      "\n",
      "         [[-0.7837, -0.7837, -0.7837, -0.7837],\n",
      "          [ 1.8423,  1.8423,  1.8423,  1.8423],\n",
      "          [ 0.5035,  0.5035,  0.5035,  0.5035],\n",
      "          [ 0.3321,  0.3321,  0.3321,  0.3321]],\n",
      "\n",
      "         [[-0.4469, -0.4469, -0.4469, -0.4469],\n",
      "          [-0.0372, -0.0372, -0.0372, -0.0372],\n",
      "          [ 0.0666,  0.0666,  0.0666,  0.0666],\n",
      "          [-0.6049, -0.6049, -0.6049, -0.6049]]]])\n"
     ]
    }
   ],
   "source": [
    "ac = torch.randn((1,3,2,2))\n",
    "print(ac)\n",
    "#ac_unfold = fold(ac.reshape(1,3,-1), (4, 4), (1, 1), dilation=(2, 2))\n",
    "#print('unfold',ac_unfold.shape)\n",
    "ac = ac.reshape(1,-1)\n",
    " \n",
    "\n",
    "print(ac.shape)\n",
    "#print(ac)\n",
    "#ac = ac.permute(0,2,1)\n",
    "w = torch.ones(1, 4)\n",
    "print(w.shape)\n",
    "print(w)\n",
    "print(ac)\n",
    "\n",
    "y = ac.T @ w\n",
    "print(y)\n",
    "#print(y.shape)\n",
    "y_view = y.view(1,3,4,4)\n",
    "y_reshape = y.reshape(1,3,4,4)\n",
    "\n",
    "print(y_view.shape, y_reshape.shape)\n",
    "print(y_view)\n",
    "print(y_reshape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37f0e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 75, 48])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1, 3, 10, 12)\n",
    "w = torch.randn(2, 3, 4, 5)\n",
    "inp_unf = torch.nn.functional.unfold(inp, (5, 5))\n",
    "print(inp_unf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40e711a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 1],\n",
      "          [5, 9]],\n",
      "\n",
      "         [[8, 5],\n",
      "          [8, 3]],\n",
      "\n",
      "         [[8, 1],\n",
      "          [7, 2]]]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[0., 0., 1., 1.],\n",
      "          [0., 0., 1., 1.],\n",
      "          [5., 5., 9., 9.],\n",
      "          [5., 5., 9., 9.]],\n",
      "\n",
      "         [[8., 8., 5., 5.],\n",
      "          [8., 8., 5., 5.],\n",
      "          [8., 8., 3., 3.],\n",
      "          [8., 8., 3., 3.]],\n",
      "\n",
      "         [[8., 8., 1., 1.],\n",
      "          [8., 8., 1., 1.],\n",
      "          [7., 7., 2., 2.],\n",
      "          [7., 7., 2., 2.]]]])\n"
     ]
    }
   ],
   "source": [
    "def upsample(a,factor_size):\n",
    "    \n",
    "    b = torch.ones(factor_size,factor_size)\n",
    "    print(b)\n",
    "    a0, a1, s1, s2 = a.shape\n",
    "    s3, s4 = b.shape\n",
    "    a = a.reshape(a0, a1, s1, 1, s2, 1)\n",
    "    b = b.reshape(1, s3, 1, s4)\n",
    "    return (a * b).reshape(a0, a1, s1 * s3, s2 * s4)\n",
    "\n",
    "a = torch.randint(10,(1,3,2,2))\n",
    "\n",
    "\n",
    "print(a)\n",
    "\n",
    "c = upsample(a,2)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbd49157",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-57-bf3db8bb2963>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-57-bf3db8bb2963>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    dl_dw1, dl_db1, dl_dw2, dl_db2):\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def backward_pass(w1, b1, w2, b2,\n",
    "                  t,\n",
    "                  x, s1, x1, s2, x2,\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10,(1,10,6,6))\n",
    "print(a.shape)\n",
    "\n",
    "upsample = Upsample(3)\n",
    "upsample2 = Upsample(2)\n",
    "convSample1 = Convolution(10, 10, kernel_size = 2, stride = 1)\n",
    "convSample2 = Convolution(10, 3, kernel_size = 3, stride = 1)\n",
    "\n",
    "\n",
    "c = upsample.forward(a)\n",
    "print('c',c.shape)\n",
    "c = convSample1.forward(c)\n",
    "print('c',c.shape)\n",
    "c = upsample2.forward(c)\n",
    "print('c',c.shape)\n",
    "c = convSample2.forward(c)\n",
    "print('c',c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea2888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid (object):\n",
    "    def forward(self, input):\n",
    "        self.x = 1/(1 + math.e**(-input))\n",
    "        return self.x\n",
    "    def backward(self, gradwrtoutput):\n",
    "        self.output = (self.x*(1-self.x))*gradwrtoutput\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ac5088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "loss torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "sigmoid = Sigmoid()\n",
    "\n",
    "img_out = sigmoid.forward(img)\n",
    "print(img_out.shape)\n",
    "\n",
    "criterion = MSE()\n",
    "img2 = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "loss = criterion.forward(img_out, img2)\n",
    "\n",
    "print('loss', loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b697a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "loss_backward = criterion.backward(img2)\n",
    "output = sigmoid.backward(loss_backward)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23b5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE (object):\n",
    "    def forward(self, predictions, targets):\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets\n",
    "        self.mse = (((self.predictions - self.targets)**2).mean())\n",
    "        return self.mse\n",
    "    def backward(self, gradwrtoutput)\n",
    "        self.output = 2*((self.predictions - self.targets).mean())\n",
    "        self.output = self.output\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37466e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1, 3, 32, 32)\n",
    "img2 = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "sigmoid = Sigmoid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80b4cf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6075368b5f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "criterion = MSE()\n",
    "\n",
    "img = sigmoid.forward(img)\n",
    "\n",
    "loss = criterion.forward(img, img2)\n",
    "print('loss', loss.shape)\n",
    "\n",
    "\n",
    "output = sigmoid.backward(criterion.backward(img, img2))\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3197242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(object):\n",
    "    def __init__(self, factor_size):\n",
    "        self.kernel = torch.ones(factor_size,factor_size)\n",
    "        #print(self.kernel.shape)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.b, self.channels, self.s1, self.s2 = x.shape\n",
    "        self.s3, self.s4 = self.kernel.shape\n",
    "        x = x.reshape(self.b, self.channels, self.s1, 1, self.s2, 1)\n",
    "        self.kernel = self.kernel.reshape(1, self.s3, 1, self.s4)\n",
    "        return (x * self.kernel).reshape(self.b, self.channels, self.s1 * self.s3,self.s2 * self.s4) \n",
    "    \n",
    "    def backward(self,gradwrtoutput):\n",
    "        dL_dS = gradwrtoutput\n",
    "        dS_dX = self.kernel # [1, K, 1, K]\n",
    "        \n",
    "        #backward x\n",
    "        dL_dS_reshape = dL_dS.reshape(self.b, self.channels, self.s1, self.s3, self.s2, self.s4) #[B, C, SI, K, SI, K]\n",
    "        print('dL_dS_reshape',dL_dS_reshape.shape)\n",
    "        \n",
    "        dL_dX = dL_dS_reshape /(dS_dX)\n",
    "        \n",
    "        print(dL_dX.shape)\n",
    "        dL_dX = dL_dX.permute(0,1,2,4,3,5)\n",
    "        print(dL_dX.shape)\n",
    "        \n",
    "        dL_dX_red = dL_dX[:,:,:,:,0,0]\n",
    "        print(dL_dX_red.shape)\n",
    "    \n",
    "        #print(dL_dX.reshape(self.b, self.channels, self.s1, self.s2).shape)\n",
    "        \n",
    "        return dL_dX_red\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9545b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[-7.0244e-01,  1.0703e+00, -7.6750e-01,  2.6161e-01],\n",
      "          [-4.9794e-01,  8.3062e-01,  5.9851e-01, -1.2932e+00],\n",
      "          [-1.6602e+00,  6.6047e-01, -6.4490e-01,  8.5714e-01],\n",
      "          [-2.5732e-02, -5.7088e-01,  4.4454e-01,  3.9045e-01]],\n",
      "\n",
      "         [[ 1.5474e-03,  5.5677e-01,  1.7350e+00, -1.0886e+00],\n",
      "          [ 1.1399e+00, -5.4481e-01,  1.7199e+00,  5.4220e-01],\n",
      "          [-1.2965e+00, -9.0065e-02,  4.8535e-01,  1.1482e+00],\n",
      "          [-8.6511e-01,  1.4079e+00,  1.1030e+00, -1.4400e+00]],\n",
      "\n",
      "         [[-6.5546e-01,  7.4798e-01, -4.9976e-01, -7.3080e-01],\n",
      "          [ 6.8153e-01,  1.1924e+00,  7.9522e-01, -5.7737e-01],\n",
      "          [-4.0230e-01, -7.3846e-01, -5.5558e-01, -6.2211e-01],\n",
      "          [ 9.5970e-01,  1.5169e+00,  9.1144e-01,  9.8928e-01]]]])\n",
      "dL_dS_reshape torch.Size([1, 3, 2, 2, 2, 2])\n",
      "torch.Size([1, 3, 2, 2, 2, 2])\n",
      "torch.Size([1, 3, 2, 2, 2, 2])\n",
      "torch.Size([1, 3, 2, 2])\n",
      "output torch.Size([1, 3, 2, 2])\n",
      "tensor([[[[-7.0244e-01, -7.6750e-01],\n",
      "          [-1.6602e+00, -6.4490e-01]],\n",
      "\n",
      "         [[ 1.5474e-03,  1.7350e+00],\n",
      "          [-1.2965e+00,  4.8535e-01]],\n",
      "\n",
      "         [[-6.5546e-01, -4.9976e-01],\n",
      "          [-4.0230e-01, -5.5558e-01]]]])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1, 3, 2, 2)\n",
    "img_error = torch.randn(1, 3, 4, 4)\n",
    "upsample = Upsample(2)\n",
    "\n",
    "img = upsample.forward(img)\n",
    "print(img.shape)\n",
    "\n",
    "print(img_error)\n",
    "output = upsample.backward(img_error)\n",
    "print('output',output.shape)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23b79009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9639adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(object):\n",
    "    def __init__(self, channels_input, channels_output, kernel_size, stride):\n",
    "        \n",
    "        self.weight = torch.empty(channels_output, channels_input, kernel_size, kernel_size).normal_()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.channels_output = channels_output\n",
    "        self.channels_input = channels_input\n",
    "\n",
    "        #print('weight',self.weight.shape)\n",
    "         \n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        \n",
    "        _,_,H,W = imgs.shape\n",
    "        #print('h w ',H,W)\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.Hout = int((H - self.kernel_size)/self.stride + 1)\n",
    "        self.Wout = int((H - self.kernel_size)/self.stride + 1)\n",
    "        print('Hout Wout', self.Hout, self.Wout)\n",
    "        self.x = imgs\n",
    "        print('x', self.x.shape)\n",
    "        self.x_unfolded = unfold(self.x, kernel_size = (self.kernel_size, self.kernel_size), stride = self.stride)\n",
    "        print('x unfold',self.x_unfolded.shape)\n",
    "        print('w shape', self.weight.view(self.channels_output, -1).shape)\n",
    "        self.y = self.x_unfolded.transpose(1, 2).matmul(self.weight.view(self.channels_output, -1).t()).transpose(1, 2)\n",
    "        #print('y',self.y.shape)\n",
    "        self.y = fold(self.y, (int(self.Hout), int(self.Wout)),(1,1), stride = 1)\n",
    "        #self.y = self.y.view(1,10,15,15)\n",
    "        return self.y  #, self_x, self_weight\n",
    "    \n",
    "\n",
    "    def backward(self,gradwrtoutput):\n",
    "        dL_dS = gradwrtoutput # [B, O, SO, SO]\n",
    "        dS_dX = self.weight   # weight.shape [O, I, K, K]\n",
    "        print('dL_dS', dL_dS.shape)\n",
    "        print('dS_dX', dS_dX.shape)\n",
    "        \n",
    "        #define the size IxKxK\n",
    "        inKerKer_size = self.channels_input*self.kernel_size*self.kernel_size\n",
    "        print('inKerKer_size',inKerKer_size)\n",
    "        \n",
    "        dL_dS_reshape = dL_dS.reshape(1,self.channels_output,-1) # [B, O, (SOxSO)]\n",
    "        print('dL_dS_reshape',dL_dS_reshape.shape)\n",
    "        dS_dX_reshape = dS_dX.reshape(self.channels_output, -1).transpose(0,1)   # [O, (IxKxK)]^T\n",
    "        print('dS_dX_reshape',dS_dX_reshape.shape)\n",
    "        \n",
    "        \n",
    "        #backward input\n",
    "        dL_dX_reshape = dS_dX_reshape @ dL_dS_reshape # [B, (IxKxK), (SOxSO)]\n",
    "        print('dL_dX_reshape',dL_dX_reshape.shape)\n",
    "        dL_dX = fold(dL_dX_reshape, kernel_size = (self.kernel_size, self.kernel_size), stride = self.stride, output_size = (self.W, self.H)) # [B, I, SI, SI]\n",
    "        print('dL_dX',dL_dX.shape)\n",
    "        \"\"\"\n",
    "        #backward weight\n",
    "        dL_dS_reshape2 = dL_dS.reshape(self.channels_output, -1) # [O, (BxSOxSO)]\n",
    "        dS_dW = x_unfold # [B, (IxKxK), (SOxSO)]\n",
    "        dS_dW_reshape = x_unfold.reshape(-1, inKerKer_size) # [(BxSOxSO), (IxKxK))] \n",
    "        dL_dW_reshape = dL_dS_reshape2 @ dS_dW_reshape # [O, (IxKxK)]\n",
    "        dL_dW = dL_dW_reshape.view(self.channels_output,  self.channels_input, self.kernel_size, self.kernel_size) # [O, I, K, K] \n",
    "        \n",
    "        \n",
    "        #backward bias\n",
    "        \"\"\"\n",
    "        \n",
    "        return dL_dX  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70e19184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hout Wout 15 15\n",
      "x torch.Size([1, 3, 32, 32])\n",
      "x unfold torch.Size([1, 48, 225])\n",
      "w shape torch.Size([10, 48])\n",
      "torch.Size([1, 10, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(1, 3, 32, 32)\n",
    "img_error = torch.randn(1, 10, 15, 15)\n",
    "conv1 = Convolution(3, 10, kernel_size = 4, stride = 2)\n",
    "\n",
    "out_img = conv1.forward(img)\n",
    "print(out_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2b11d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dS torch.Size([1, 10, 15, 15])\n",
      "dS_dX torch.Size([10, 3, 4, 4])\n",
      "inKerKer_size 48\n",
      "dL_dS_reshape torch.Size([1, 10, 225])\n",
      "dS_dX_reshape torch.Size([48, 10])\n",
      "dL_dX_reshape torch.Size([1, 48, 225])\n",
      "dL_dX torch.Size([1, 3, 32, 32])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img_error = torch.randn(1, 10, 15, 15)\n",
    "\n",
    "out_img = conv1.backward(img_error)\n",
    "print(out_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a066237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hout Wout 16 16\n",
      "x torch.Size([1, 3, 32, 32])\n",
      "x unfold torch.Size([1, 12, 256])\n",
      "w shape torch.Size([3, 12])\n",
      "x torch.Size([1, 3, 16, 16])\n",
      "x torch.Size([1, 3, 32, 32])\n",
      "loss torch.Size([])\n",
      "torch.Size([1, 3, 32, 32])\n",
      "dL_dS_reshape torch.Size([1, 3, 16, 2, 16, 2])\n",
      "torch.Size([1, 3, 16, 2, 16, 2])\n",
      "torch.Size([1, 3, 16, 16, 2, 2])\n",
      "torch.Size([1, 3, 16, 16])\n",
      "output torch.Size([1, 3, 16, 16])\n",
      "dL_dS torch.Size([1, 3, 16, 16])\n",
      "dS_dX torch.Size([3, 3, 2, 2])\n",
      "inKerKer_size 12\n",
      "dL_dS_reshape torch.Size([1, 3, 256])\n",
      "dS_dX_reshape torch.Size([12, 3])\n",
      "dL_dX_reshape torch.Size([1, 12, 256])\n",
      "dL_dX torch.Size([1, 3, 32, 32])\n",
      "out img torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "conv1 = Convolution(3, 3, kernel_size = 2, stride = 2) # 1,3,16,16\n",
    "upsample = Upsample(2) # 1,3, 32, 32\n",
    "\n",
    "criterion = MSE()\n",
    "sigmoid = Sigmoid()\n",
    "\n",
    "img = torch.randn(1, 3, 32, 32)\n",
    "img_error = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "\n",
    "x = conv1.forward(img)\n",
    "print('x', x.shape)\n",
    "x = upsample.forward(x)\n",
    "print('x', x.shape)\n",
    "\n",
    "img = sigmoid.forward(x)\n",
    "\n",
    "\n",
    "loss = criterion.forward(img, img2)\n",
    "print('loss', loss.shape)\n",
    "\n",
    "\n",
    "output = sigmoid.backward(criterion.backward(img))\n",
    "print(output.shape)\n",
    "\n",
    "output = upsample.backward(output)\n",
    "print('output', output.shape)\n",
    "\n",
    "out_img = conv1.backward(output)\n",
    "\n",
    "print('out img', out_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee9c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
